Bài viết này cần thêm chú thích nguồn gốc để kiểm chứng thông tin. Mời bạn giúp hoàn thiện bài viết này bằng cách bổ sung chú thích tới các nguồn đáng tin cậy. Các nội dung không có nguồn có thể bị nghi ngờ và xóa bỏ. Học có giám sát là một kĩ thuật của ngành học máy để xây dựng một hàm (function) từ dữ liệu huấn luyện. Dữ liệu huấn luyện bao gồm các cặp gồm đối tượng đầu vào (thường dạng vec-tơ), và đầu ra mong muốn. Đầu ra của một hàm có thể là một giá trị liên tục (gọi là hồi qui), hay có thể là dự đoán một nhãn phân loại cho một đối tượng đầu vào (gọi là phân loại). Nhiệm vụ của chương trình học có giám sát là dự đoán giá trị của hàm cho một đối tượng bất kì là đầu vào hợp lệ, sau khi đã xem xét một số ví dụ huấn luyện (nghĩa là, các cặp đầu vào và đầu ra tương ứng). Để đạt được điều này, chương trình học phải tổng quát hóa từ các dữ liệu sẵn có để dự đoán được những tình huống chưa gặp phải theo một cách "hợp lý" (xem thiên kiến qui nạp - inductive bias). (So sánh với học không có giám sát.) Học có giám sát có thể tạo ra hai loại mô hình. Phổ biến nhất, học có giám sát tạo ra một mô hình toàn cục (global model) để ánh xạ đối tượng đầu vào đến đầu ra mong muốn. Tuy nhiên, trong một số trường hợp, việc ánh xạ được thực hiện dưới dạng một tập các mô hình cục bộ (như trong phương pháp lập luận theo tình huống (case-based reasoning) hay giải thuật láng giềng gần nhất). Để có thể giải quyết một bài toán nào đó của học có giám sát (ví dụ: học để nhận dạng chữ viết tay) người ta phải xem xét nhiều bước khác nhau: Xác định loại của các ví dụ huấn luyện. Trước khi làm bất cứ điều gì, người kĩ sư nên quyết định loại dữ liệu nào sẽ được sử dụng làm ví dụ. Chẳng hạn, đó có thể là một ký tự viết tay đơn lẻ, toàn bộ một từ viết tay, hay toàn bộ một dòng chữ viết tay. Thu thập tập huấn luyện. Tập huấn luyện cần đặc trưng cho thực tế sử dụng của hàm chức năng. Vì thế, một tập các đối tượng đầu vào được thu thập và đầu ra tương ứng được thu thập, hoặc từ các chuyên gia hoặc từ việc đo đạc tính toán. Xác định việc biểu diễn các đặc trưng đầu vào cho hàm chức năng cần tìm. Sự chính xác của hàm chức năng phụ thuộc lớn vào cách các đối tượng đầu vào được biểu diễn. Thông thường, đối tượng đầu vào được chuyển đổi thành một vec-tơ đặc trưng, chứa một số các đặc trưng nhằm mô tả cho đối tượng đó. Số lượng các đặc trưng không nên quá lớn, do sự bùng nổ tổ hợp (curse of dimensionality); nhưng phải đủ lớn để dự đoán chính xác đầu ra. Xác định cấu trúc của hàm chức năng cần tìm và giải thuật học tương ứng. Ví dụ, người kĩ sư có thể lựa chọn việc sử dụng mạng nơ-ron nhân tạo hay cây quyết định. Hoàn thiện thiết kế. Người kĩ sư sẽ chạy giải thuật học từ tập huấn luyện thu thập được. Các tham số của giải thuật học có thể được điều chỉnh bằng cách tối ưu hóa hiệu năng trên một tập con (gọi là tập kiểm chứng -validation set) của tập huấn luyện, hay thông qua kiểm chứng chéo (cross-validation). Sau khi học và điều chỉnh tham số, hiệu năng của giải thuật có thể được đo đạc trên một tập kiểm tra độc lập với tập huấn luyện. Mục lục 1 Cực tiểu hóa rủi ro kinh nghiệm 2 Hướng tiếp cận và giải thuật 3 Ứng dụng 4 Vấn đề chung 5 Tham khảo 6 Liên kết ngoài Cực tiểu hóa rủi ro kinh nghiệm Mục tiêu của việc học có giám sát một mô hình toàn cục là tìm ra một hàm g, khi cho sẵn một tập các điểm có dạng (x, g(x)). Giả thiết rằng đã biết trước đặc điểm của hàm g đối với một tập điểm. Tập điểm đó đã được lấy mẫu độc lập và có cùng phân bố (independent and identically distributed (i.i.d.)) theo một xác suất phân bố p chưa biết từ một tập lớn hơn và có thể vô hạn. Ngoài ra, giả sử tồn tại một hàm hàm tổn thất (loss function) theo tác vụ L có dạng: trong đó Y là trùng với miền xác định của g và L ánh xạ tới các số thực không âm (có thể đặt thêm hạn chế cho L). Giá trị L(z, y) là tổn thất nảy sinh khi đoán giá trị của g tại một điểm cho trước là z trong khi giá trị thực của nó là y. Hàm rủi ro f được định nghĩa là giá trị kỳ vọng của hàm tổn thất và có công thức như sau: nếu xác suất phân bố p là rời rạc (trường hợp xác suất phân bố liên tục cần một tích phân xác định (definite integral) và một hàm mật độ xác suất. Mục tiêu là tìm một hàm f* trong số một lớp con cố định các hàm để cho rủi ro R(f*) là cực tiểu. Tuy nhiên, do thường chỉ biết được đặc điểm của hàm g cho một tập hữu hạn điểm (x1, y1),..., (xn, yn), người ta chỉ có thể xác định gần đúng rủi ro thực sự, ví dụ, với rủi ro kinh nghiệm (empirical risk): Nguyên lý của cực tiểu hóa rủi ro kinh nghiệm là chọn hàm f* sao cho rủi ro kinh nghiệm là nhỏ nhất. Lý thuyết học bằng thống kê tìm hiểu xem việc cực tiểu hóa rủi ro kinh nghiệm có thể đạt được trong những điều kiện nào và có thể trông đợi các tính toán xấp xỉ tốt đến đâu. Hướng tiếp cận và giải thuật học bằng phân tích (analytical learning) mạng nơ-ron nhân tạo Instantaneously trained neural networks kỹ thuật lan truyền ngược (backpropagation) boosting thống kê Bayes lập luận theo tình huống (case-based reasoning) học cây quyết định inductive logic programming hồi quy Gauss (Gaussian process regression) learning automata theory Minimum message length (cây quyết định, đồ thị quyết định, v.v.) naive Bayes classifier thuật toán láng giềng gần nhất probably approximately correct learning (PAC) learning symbolic machine learning algorithms subsymbolic machine learning algorithms support vector machines Random Forests Ứng dụng Tin sinh học Nhận dạng chữ viết tay Thu thập thông tin (information retrieval) Nhận dạng đối tượng trong computer vision Nhận dạng ký tự quang học Phát hiện spam Nhận dạng mẫu Nhận dạng tiếng nói Vấn đề chung computational learning theory (ngành toán học liên quan đến việc phân tích các thuật toán học máy) thiên kiến qui nạp (inductive bias) overfitting (hàm học được quá thích nghi với tập huấn luyện) version space Tham khảo Liên kết ngoài Chương trình mạng nơ ron đa lớp (Multi Layer Neural Network) và mạng nơ ron tự tổ chức (Self Organizing Maps) có giải thích bằng tiếng Việt. Sử dụng phần mềm mạng nơ ron 3 lớp Spice-MLP Sử dụng phần mềm mạng tự tổ chức Spice-SOM Hướng dẫn sử dụng mạng nơ ron trong các ứng dụng thực tế trong đó có minh họa phân loại ảnh khuôn mặt, ảnh người đi bộ, ảnh xe hơi, dự báo chứng khoán và một số ví dụ khác